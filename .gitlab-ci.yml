# Define the Docker image to use for the jobs
image:
  name: hashicorp/terraform:latest
  entrypoint:
    - '/usr/bin/env'
    - 'PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'

# Define the stages of the pipeline
stages:
  - validate
  - plan
  - apply
  - destroy

# Cache Terraform plugins to speed up future jobs
cache:
  key: "${CI_COMMIT_REF_SLUG}"
  paths:
    - .terraform

# This script runs before each job
before_script:
  # Set AWS credentials from GitLab CI/CD variables
  - export AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
  - export AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
  - terraform init

# Job to validate the Terraform code syntax
validate:
  stage: validate
  script:
    - terraform validate

# Job to create an execution plan
plan:
  stage: plan
  script:
    - terraform plan -out="planfile"
  artifacts:
    paths:
      - planfile
      - "**/*.zip" 

# Job to apply the changes. Requires manual trigger for safety.
apply:
  stage: apply
  script:
    - terraform apply -input=false "planfile"
  dependencies:
    - plan
  when: manual

# Job to destroy the infrastructure. Requires manual trigger for safety.
destroy:
  stage: destroy
  script:
    - terraform destroy -auto-approve
  when: manual